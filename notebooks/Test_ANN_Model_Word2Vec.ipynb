{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@erreborda</td>\n",
       "      <td>termine bien abrumado después de hoy</td>\n",
       "      <td>Jan 6, 2024 · 2:53 AM UTC</td>\n",
       "      <td>overwhelmed</td>\n",
       "      <td>scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@shpiderduck</td>\n",
       "      <td>me siento abrumado❤</td>\n",
       "      <td>Jan 6, 2024 · 2:35 AM UTC</td>\n",
       "      <td>overwhelmed</td>\n",
       "      <td>scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Alex_R_art</td>\n",
       "      <td>Me siento un poco abrumado por la cantidad de ...</td>\n",
       "      <td>Jan 6, 2024 · 12:20 AM UTC</td>\n",
       "      <td>overwhelmed</td>\n",
       "      <td>scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@anggelinaa97</td>\n",
       "      <td>Salvador la única persona que no la ha abrumad...</td>\n",
       "      <td>Jan 5, 2024 · 10:38 PM UTC</td>\n",
       "      <td>overwhelmed</td>\n",
       "      <td>scared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@diegoreyesvqz</td>\n",
       "      <td>Denme un helado o algo que ando full abrumado.</td>\n",
       "      <td>Jan 5, 2024 · 8:38 PM UTC</td>\n",
       "      <td>overwhelmed</td>\n",
       "      <td>scared</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user                                               text  \\\n",
       "0      @erreborda               termine bien abrumado después de hoy   \n",
       "1    @shpiderduck                                me siento abrumado❤   \n",
       "2     @Alex_R_art  Me siento un poco abrumado por la cantidad de ...   \n",
       "3   @anggelinaa97  Salvador la única persona que no la ha abrumad...   \n",
       "4  @diegoreyesvqz     Denme un helado o algo que ando full abrumado.   \n",
       "\n",
       "                         date      emotion sentiment  \n",
       "0   Jan 6, 2024 · 2:53 AM UTC  overwhelmed    scared  \n",
       "1   Jan 6, 2024 · 2:35 AM UTC  overwhelmed    scared  \n",
       "2  Jan 6, 2024 · 12:20 AM UTC  overwhelmed    scared  \n",
       "3  Jan 5, 2024 · 10:38 PM UTC  overwhelmed    scared  \n",
       "4   Jan 5, 2024 · 8:38 PM UTC  overwhelmed    scared  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../notebooks/data/sentiment_analysis_dataset.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['emotion'].value_counts().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "peaceful    660\n",
       "mad         530\n",
       "powerful    420\n",
       "sad         360\n",
       "joyful      350\n",
       "scared      270\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento (Limpieza, Tokenización, Stopwords y Lematización)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traducción de las etiquetas a español\n",
    "translation = {\n",
    "    'joyful': 'Alegre',\n",
    "    'daring': 'Osado',\n",
    "    'optimistic': 'Optimista',\n",
    "    'playful': 'Jugueton',\n",
    "    'powerful': 'Poderoso',\n",
    "    'surprised': 'Sorprendido',\n",
    "    'successful': 'Exitoso',\n",
    "    'confident': 'Confiado',\n",
    "    'peaceful': 'Tranquilo',\n",
    "    'secure': 'Seguro',\n",
    "    'thankful': 'Agradecido',\n",
    "    'loving': 'Amoroso',\n",
    "    'relaxed': 'Relajado',\n",
    "    'responsive': 'Sensible',\n",
    "    'sad': 'Triste',\n",
    "    'sleepy': 'Adormilado',\n",
    "    'isolated': 'Aislado',\n",
    "    'stupid': 'Estupido',\n",
    "    'mad': 'Histerico',\n",
    "    'distant': 'Distante',\n",
    "    'frustrated': 'Frustrado',\n",
    "    'irritated': 'Irritado',\n",
    "    'jealous': 'Celoso',\n",
    "    'scared': 'Asustado',\n",
    "    'embarrassed': 'Avergonzado',\n",
    "    'overwhelmed': 'Agobiado',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>emotion</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@erreborda</td>\n",
       "      <td>termine bien abrumado después de hoy</td>\n",
       "      <td>Jan 6, 2024 · 2:53 AM UTC</td>\n",
       "      <td>Agobiado</td>\n",
       "      <td>Asustado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@shpiderduck</td>\n",
       "      <td>me siento abrumado❤</td>\n",
       "      <td>Jan 6, 2024 · 2:35 AM UTC</td>\n",
       "      <td>Agobiado</td>\n",
       "      <td>Asustado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Alex_R_art</td>\n",
       "      <td>Me siento un poco abrumado por la cantidad de ...</td>\n",
       "      <td>Jan 6, 2024 · 12:20 AM UTC</td>\n",
       "      <td>Agobiado</td>\n",
       "      <td>Asustado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@anggelinaa97</td>\n",
       "      <td>Salvador la única persona que no la ha abrumad...</td>\n",
       "      <td>Jan 5, 2024 · 10:38 PM UTC</td>\n",
       "      <td>Agobiado</td>\n",
       "      <td>Asustado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@diegoreyesvqz</td>\n",
       "      <td>Denme un helado o algo que ando full abrumado.</td>\n",
       "      <td>Jan 5, 2024 · 8:38 PM UTC</td>\n",
       "      <td>Agobiado</td>\n",
       "      <td>Asustado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user                                               text  \\\n",
       "0      @erreborda               termine bien abrumado después de hoy   \n",
       "1    @shpiderduck                                me siento abrumado❤   \n",
       "2     @Alex_R_art  Me siento un poco abrumado por la cantidad de ...   \n",
       "3   @anggelinaa97  Salvador la única persona que no la ha abrumad...   \n",
       "4  @diegoreyesvqz     Denme un helado o algo que ando full abrumado.   \n",
       "\n",
       "                         date   emotion sentiment  \n",
       "0   Jan 6, 2024 · 2:53 AM UTC  Agobiado  Asustado  \n",
       "1   Jan 6, 2024 · 2:35 AM UTC  Agobiado  Asustado  \n",
       "2  Jan 6, 2024 · 12:20 AM UTC  Agobiado  Asustado  \n",
       "3  Jan 5, 2024 · 10:38 PM UTC  Agobiado  Asustado  \n",
       "4   Jan 5, 2024 · 8:38 PM UTC  Agobiado  Asustado  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['emotion', 'sentiment']] = data[['emotion', 'sentiment']].replace(to_replace = translation)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_map ={\n",
    "#     'Alegre': 1, # Sentimiento 1\n",
    "#     'Osado': 1,\n",
    "#     'Optimista': 2,\n",
    "#     'Jugueton': 3,\n",
    "#     'Poderoso': 2, # Sentimiento 2\n",
    "#     'Sorprendido': 4,\n",
    "#     'Exitoso': 5, \n",
    "#     'Confiado': 6, \n",
    "#     'Tranquilo': 3, # Sentimiento 3\n",
    "#     'Seguro': 7,\n",
    "#     'Agradecido': 8,\n",
    "#     'Amoroso': 9,\n",
    "#     'Relajado': 10,\n",
    "#     'Sensible': 11,\n",
    "#     'Triste': 4, # Sentimiento 4\n",
    "#     'Adormilado': 12,\n",
    "#     'Aislado': 13,\n",
    "#     'Estupido': 14,\n",
    "#     'Histerico': 5, # Sentimiento 5\n",
    "#     'Distante': 15,\n",
    "#     'Frustrado': 16,\n",
    "#     'Irritado': 17,\n",
    "#     'Celoso': 18,\n",
    "#     'Asustado': 6, # Sentimiento 6\n",
    "#     'Avergonzado': 19,\n",
    "#     'Agobiado': 20,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotions = ['Osado', 'Optimista', 'Jugueton', 'Sorprendido', 'Exitoso', 'Confiado', 'Seguro', 'Agradecido', 'Amoroso', 'Relajado', 'Sensible', \n",
    "#            'Adormilado', 'Aislado', 'Histerico', 'Distante', 'Frustrado', 'Irritado', 'Celoso', 'Avergonzado', 'Agobiado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reversed_map = {value: sentiment for sentiment, value in target_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_map = {\n",
    "    'Osado': 'Felicidad',\n",
    "    'Optimista': 'Felicidad',\n",
    "    'Jugueton': 'Felicidad',\n",
    "    'Sorprendido': 'Empoderado',\n",
    "    'Exitoso': 'Empoderado',\n",
    "    'Confiado': 'Empoderado',\n",
    "    'Seguro': 'Paz',\n",
    "    'Agradecido': 'Paz',\n",
    "    'Amoroso': 'Paz',\n",
    "    'Relajado': 'Paz',\n",
    "    'Sensible': 'Paz',\n",
    "    'Adormilado': 'Tristeza',\n",
    "    'Aislado': 'Tristeza',\n",
    "    'Histerico': 'Tristeza',\n",
    "    'Distante': 'Furia',\n",
    "    'Frustrado': 'Furia',\n",
    "    'Irritado': 'Furia',\n",
    "    'Celoso': 'Furia',\n",
    "    'Avergonzado': 'Miedo',\n",
    "    'Agobiado': 'Miedo',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['emotion'] = data['emotion'].map(target_map)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['text', 'emotion']].copy()\n",
    "df.rename(columns = {'emotion': 'target'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\WilmarAl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\WilmarAl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Cargar el modelo de spaCy para español\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Definir stopwords en español\n",
    "stop_words = set(stopwords.words('spanish')) | STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    text = text.lower()\n",
    "    text = text.replace('á','a').replace('é','e')\n",
    "    text = text.replace('í','i').replace('ó','o')\n",
    "    text = text.replace('ú','u').replace('$','')\n",
    "    text = text.replace('—','').replace('-',' ')\n",
    "    text = text.replace('%','').replace('&','')\n",
    "    text = text.replace('\\n',' ').replace('\\t',' ')\n",
    "    text = text.replace(\"'\",\"\").replace('\"','')\n",
    "    text = text.replace(',','').replace('.','')\n",
    "    text = text.replace(';','').replace(':','')\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)  # Eliminar menciones\n",
    "    text = re.sub(r'#[A-Za-z0-9_]+', '', text)  # Eliminar hashtags\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)  # Eliminar URLs\n",
    "    text = re.sub(r'[^a-zA-ZáéíóúÁÉÍÓÚñÑ ]', '', text)  # Eliminar caracteres especiales y emojis\n",
    "\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Eliminar stopwords y lematizar\n",
    "    palabras_procesadas = [token.lemma_ for token in doc if token.text.lower() not in stop_words and not token.is_punct]\n",
    "    \n",
    "    return \" \".join(palabras_procesadas)\n",
    "\n",
    "def text_to_vector(tokens, model):\n",
    "    # Obtener el vector promedio de todas las palabras en el texto\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)  # Promedio de los vectores\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Si no hay palabras conocidas, devolver un vector de ceros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>termine bien abrumado después de hoy</td>\n",
       "      <td>Agobiado</td>\n",
       "      <td>terminar abrumado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>me siento abrumado❤</td>\n",
       "      <td>Agobiado</td>\n",
       "      <td>sentir abrumado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Me siento un poco abrumado por la cantidad de ...</td>\n",
       "      <td>Agobiado</td>\n",
       "      <td>sentir abrumado cantidad cosa querer dibujar j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salvador la única persona que no la ha abrumad...</td>\n",
       "      <td>Agobiado</td>\n",
       "      <td>salvador unico persona abrumar versión</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denme un helado o algo que ando full abrumado.</td>\n",
       "      <td>Agobiado</td>\n",
       "      <td>denmir helado ar full abrumado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    target  \\\n",
       "0               termine bien abrumado después de hoy  Agobiado   \n",
       "1                                me siento abrumado❤  Agobiado   \n",
       "2  Me siento un poco abrumado por la cantidad de ...  Agobiado   \n",
       "3  Salvador la única persona que no la ha abrumad...  Agobiado   \n",
       "4     Denme un helado o algo que ando full abrumado.  Agobiado   \n",
       "\n",
       "                                              tokens  \n",
       "0                                  terminar abrumado  \n",
       "1                                    sentir abrumado  \n",
       "2  sentir abrumado cantidad cosa querer dibujar j...  \n",
       "3             salvador unico persona abrumar versión  \n",
       "4                     denmir helado ar full abrumado  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(sentences = df['tokens'], vector_size=5, window=5, min_count=1, workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la vectorización a cada fila del dataframe\n",
    "df['vector'] = df['tokens'].apply(lambda x: text_to_vector(x, word2vec_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>\"¿Ahora es cuando te rompo la columna para que...</td>\n",
       "      <td>Seguro</td>\n",
       "      <td>rompo columna chupes   alzo ceja sonrisa tono ...</td>\n",
       "      <td>[-0.22160594, -0.14141804, 0.37716672, -0.3684...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>viernes 23:58  me puse a jugar al solitario se...</td>\n",
       "      <td>Distante</td>\n",
       "      <td>viernes    poner jugar solitario venir nochon</td>\n",
       "      <td>[-0.273233, -0.11118002, 0.37799674, -0.392835...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    target  \\\n",
       "1769  \"¿Ahora es cuando te rompo la columna para que...    Seguro   \n",
       "758   viernes 23:58  me puse a jugar al solitario se...  Distante   \n",
       "\n",
       "                                                 tokens  \\\n",
       "1769  rompo columna chupes   alzo ceja sonrisa tono ...   \n",
       "758       viernes    poner jugar solitario venir nochon   \n",
       "\n",
       "                                                 vector  \n",
       "1769  [-0.22160594, -0.14141804, 0.37716672, -0.3684...  \n",
       "758   [-0.273233, -0.11118002, 0.37799674, -0.392835...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df['vector'].tolist())  # Matriz de características (vectores)\n",
    "y = df['target']  # Etiquetas (emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # Convertir etiquetas a números\n",
    "y_categorical = to_categorical(y_encoded)   # Convertir a one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y desempeño de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WilmarAl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "model_ann = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_dim = 10),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(20, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model_ann.compile(\n",
    "    optimizer='adam',  # Optimizador Adam\n",
    "    loss='categorical_crossentropy',  # Función de pérdida para clasificación multiclase\n",
    "    metrics=['accuracy']  # Métrica de evaluación\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0438 - loss: 3.0146 - val_accuracy: 0.0405 - val_loss: 2.9974\n",
      "Epoch 2/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0625 - loss: 2.9976 - val_accuracy: 0.0444 - val_loss: 2.9962\n",
      "Epoch 3/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0586 - loss: 2.9938 - val_accuracy: 0.0425 - val_loss: 2.9974\n",
      "Epoch 4/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0470 - loss: 2.9924 - val_accuracy: 0.0541 - val_loss: 2.9965\n",
      "Epoch 5/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0663 - loss: 2.9918 - val_accuracy: 0.0598 - val_loss: 2.9962\n",
      "Epoch 6/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0572 - loss: 2.9904 - val_accuracy: 0.0598 - val_loss: 2.9971\n",
      "Epoch 7/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0559 - loss: 2.9913 - val_accuracy: 0.0618 - val_loss: 2.9973\n",
      "Epoch 8/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0531 - loss: 2.9905 - val_accuracy: 0.0656 - val_loss: 2.9970\n",
      "Epoch 9/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0542 - loss: 2.9872 - val_accuracy: 0.0425 - val_loss: 2.9979\n",
      "Epoch 10/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0581 - loss: 2.9873 - val_accuracy: 0.0637 - val_loss: 2.9970\n",
      "Epoch 11/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0591 - loss: 2.9900 - val_accuracy: 0.0521 - val_loss: 2.9979\n",
      "Epoch 12/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0704 - loss: 2.9847 - val_accuracy: 0.0637 - val_loss: 2.9962\n",
      "Epoch 13/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0556 - loss: 2.9849 - val_accuracy: 0.0618 - val_loss: 2.9979\n",
      "Epoch 14/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0601 - loss: 2.9850 - val_accuracy: 0.0695 - val_loss: 2.9953\n",
      "Epoch 15/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0681 - loss: 2.9872 - val_accuracy: 0.0676 - val_loss: 2.9967\n",
      "Epoch 16/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0636 - loss: 2.9790 - val_accuracy: 0.0618 - val_loss: 2.9964\n",
      "Epoch 17/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0670 - loss: 2.9854 - val_accuracy: 0.0656 - val_loss: 2.9942\n",
      "Epoch 18/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0553 - loss: 2.9796 - val_accuracy: 0.0560 - val_loss: 2.9924\n",
      "Epoch 19/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0582 - loss: 2.9776 - val_accuracy: 0.0734 - val_loss: 2.9947\n",
      "Epoch 20/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0615 - loss: 2.9849 - val_accuracy: 0.0618 - val_loss: 2.9965\n"
     ]
    }
   ],
   "source": [
    "# Entrenar la red neuronal\n",
    "history = model_ann.fit(X_train, Y_train, epochs=20, batch_size=16, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    }
   ],
   "source": [
    "# 10. Evaluar el modelo\n",
    "y_pred = model_ann.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convertir one-hot encoding a clases\n",
    "y_test_classes = np.argmax(Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Adormilado       0.14      0.16      0.15        31\n",
      "    Agobiado       0.00      0.00      0.00        22\n",
      "  Agradecido       0.06      0.52      0.11        29\n",
      "     Aislado       0.00      0.00      0.00        17\n",
      "     Amoroso       0.00      0.00      0.00        18\n",
      " Avergonzado       0.00      0.00      0.00        34\n",
      "      Celoso       0.05      0.55      0.10        22\n",
      "    Confiado       0.00      0.00      0.00        22\n",
      "    Distante       0.00      0.00      0.00        21\n",
      "    Estupido       0.00      0.00      0.00        20\n",
      "     Exitoso       0.00      0.00      0.00        38\n",
      "   Frustrado       0.00      0.00      0.00        24\n",
      "    Irritado       0.00      0.00      0.00        39\n",
      "    Jugueton       0.00      0.00      0.00        21\n",
      "   Optimista       0.00      0.00      0.00        22\n",
      "       Osado       0.00      0.00      0.00        18\n",
      "    Relajado       0.00      0.00      0.00        31\n",
      "      Seguro       0.00      0.00      0.00        31\n",
      "    Sensible       0.00      0.00      0.00        26\n",
      " Sorprendido       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.06       518\n",
      "   macro avg       0.01      0.06      0.02       518\n",
      "weighted avg       0.01      0.06      0.02       518\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WilmarAl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\WilmarAl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\WilmarAl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el reporte de clasificación\n",
    "print(classification_report(y_test_classes, y_pred_classes, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Texto: La verdad extraño la persona que solías ser, que me recordaba que debo descansar sin sentirme culpable, que se molestó en conocer mi lenguaje corporal y me hizo sentir que quererme no era difícil. Te lo agradezco, pero te llevaste mi parte más vulnerable y ahora no sé qué hacer.\n",
      "Clase predicha: Celoso\n",
      "Probabilidades por clase: [[0.05962094 0.0564329  0.0606391  0.05060411 0.05685374 0.04160983\n",
      "  0.06138128 0.05848372 0.04861556 0.03139533 0.05058502 0.03859854\n",
      "  0.04753034 0.05280064 0.0418862  0.04467924 0.05242371 0.05649063\n",
      "  0.04271631 0.04665283]]\n"
     ]
    }
   ],
   "source": [
    "# Texto de entrada\n",
    "user_text = 'La verdad extraño la persona que solías ser, que me recordaba que debo descansar sin sentirme culpable, que se molestó en conocer mi lenguaje corporal y me hizo sentir que quererme no era difícil. Te lo agradezco, pero te llevaste mi parte más vulnerable y ahora no sé qué hacer.'\n",
    "\n",
    "# 1. Preprocesar el texto de entrada\n",
    "user_tokens = preprocess_text(user_text)  # Tokenización\n",
    "user_vector = text_to_vector(user_tokens, word2vec_model)  # Convertir a vector\n",
    "\n",
    "# 2. Convertir el vector en un formato compatible con el modelo\n",
    "user_vector = np.array([user_vector])  # Añadir una dimensión extra (batch size = 1)\n",
    "\n",
    "# 3. Hacer la predicción con la red neuronal\n",
    "prediction = model_ann.predict(user_vector)  # Obtener las probabilidades de cada clase\n",
    "predicted_class_index = np.argmax(prediction, axis=1)  # Obtener la clase predicha\n",
    "\n",
    "# 4. Convertir el índice de la clase predicha a la etiqueta original\n",
    "predicted_class = label_encoder.inverse_transform(predicted_class_index)\n",
    "\n",
    "# 5. Mostrar el resultado\n",
    "print(f\"Texto: {user_text}\")\n",
    "print(f\"Clase predicha: {predicted_class[0]}\")\n",
    "print(f\"Probabilidades por clase: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
